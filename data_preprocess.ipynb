{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks\n",
    "from interval import interval\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing steps\n",
    "\n",
    "![](./files/preprocessing1.png)\n",
    "![](./files/preprocessing2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('./physionet_dataset_processed/1001m.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) FHR spike removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fhr_spike_removal(mat):\n",
    "    # Get FHR signal\n",
    "    fhr = mat['val'][0]\n",
    "\n",
    "    i = 0\n",
    "    while fhr[-1] == 0:\n",
    "        i = i + 1\n",
    "        fhr = np.delete(fhr,-1)\n",
    "    i = 0\n",
    "    while fhr[0] == 0:\n",
    "        i = i + 1\n",
    "        fhr = np.delete(fhr,0)\n",
    "\n",
    "    spike = []\n",
    "    for x in range(len(fhr)-1):\n",
    "        if abs(fhr[x+1]-fhr[x]) > 25*100:\n",
    "            spike.append(x)\n",
    "\n",
    "    stable = []\n",
    "    for x in range(len(fhr)-4):\n",
    "        if abs(fhr[x+1]-fhr[x]) < 10*100 and abs(fhr[x+2]-fhr[x+1]) < 10*100 and abs(fhr[x+3]-fhr[x+2]) < 10*100 and abs(fhr[x+4]-fhr[x+3]) < 10*100 and fhr[x] != 0:\n",
    "            stable.append(x)\n",
    "\n",
    "    n = float('-inf')\n",
    "    for s in spike:\n",
    "        if s <= n :\n",
    "            continue\n",
    "        l = [i for i in stable if i > s]\n",
    "        if len(l) > 0:\n",
    "            n = l[0]\n",
    "        else:\n",
    "            break\n",
    "        for t in range(s+1,n,1):\n",
    "            fhr[t] = fhr[t-1] + (fhr[n]-fhr[s])/(n-s)\n",
    "    \n",
    "    return fhr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhr = fhr_spike_removal(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Filtering of uterine contraction signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_uterine_contractions(mat):\n",
    "    # Get UC signal\n",
    "    uc = mat['val'][1]\n",
    "\n",
    "    i = 0\n",
    "    window_size = 17\n",
    "    moving_averages = []\n",
    "    while i < len(uc) - window_size + 1:\n",
    "        this_window = uc[i : i + window_size]\n",
    "        window_average = sum(this_window) / window_size\n",
    "        moving_averages.append(window_average)\n",
    "        i += 1\n",
    "\n",
    "    return moving_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "uc = filter_uterine_contractions(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Detection of uterine contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uterine_contraction_detection(uc):\n",
    "    #Detection of contractions\n",
    "    nuc = [50 * round(x/50) for x in uc]\n",
    "    mode,_ = stats.mode([x for x in nuc if x > 900])\n",
    "    mode = mode[0]\n",
    "    contraction_intervals = []\n",
    "    i = 0\n",
    "    contraction_total_time = 0\n",
    "    while i+20*4 < len(nuc):\n",
    "        shifted_fhr = [x-mode for x in nuc[i:i+20*4]]\n",
    "        if all([x>0 for x in shifted_fhr]) == True:\n",
    "            max_shift = max(shifted_fhr)\n",
    "            j = i+20*4\n",
    "            while  j<len(nuc) and nuc[j]-mode>0:\n",
    "                if nuc[j]-mode>max_shift:\n",
    "                    max_shift = nuc[j]-mode\n",
    "                j = j + 1\n",
    "            if max_shift > 3*100:\n",
    "                contraction_intervals.append([i,j])\n",
    "                contraction_total_time = contraction_total_time + j - i\n",
    "            i = j\n",
    "        else:\n",
    "            i = i + 1\n",
    "    return contraction_intervals, contraction_total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_intervals, contraction_total_time = uterine_contraction_detection(uc)\n",
    "contraction_number_per_second = 4*len(contraction_intervals)/len(uc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Evaluation of abnormal and mean short-term variability(STV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stv_calculation(fhr):\n",
    "    #stv calculation\n",
    "    stv = []\n",
    "    #for x in range(len(fhr)-1):\n",
    "    #    stv.append(abs(fhr[x] - fhr[x+1]))\n",
    "    for x in range(1,len(fhr)-1):\n",
    "        stv.append(abs(fhr[x-1] - fhr[x+1]))\n",
    "\n",
    "    #mean\n",
    "    stv_mean = sum(stv)/len(stv)\n",
    "    stv_mean = stv_mean/100\n",
    "    #abnormal percentage\n",
    "    stv_abnormal = [x for x in stv if x < 100]\n",
    "    stv_abn_per = 100*len(stv_abnormal)/len(stv)\n",
    "\n",
    "    return stv_mean, stv_abn_per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [],
   "source": [
    "stv_mean, stv_abn_per = stv_calculation(fhr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Filtering of fhr signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_fhr_signals(fhr):\n",
    "    i = 0\n",
    "    window_size = 5\n",
    "    moving_averages = []\n",
    "    while i < len(fhr) - window_size + 1:\n",
    "        this_window = fhr[i : i + window_size]\n",
    "        window_average = sum(this_window) / window_size\n",
    "        moving_averages.append(window_average)\n",
    "        i += 1\n",
    "\n",
    "    return moving_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [],
   "source": [
    "fhr = filter_fhr_signals(fhr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Quantification of fetal movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) Estimation of the FHR baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fhr_baseline_estimation(fhr):\n",
    "    def find_baseline(f,h,BL,imax):\n",
    "        stv_abn_fr = stv_abn_per/100\n",
    "        if BL >=  110:\n",
    "            if BL > 152: \n",
    "                for i in range(1,imax):\n",
    "                    if f[i] >= 110 and f[i] < BL and h[i] > 1.6*stv_abn_fr*h[0]:\n",
    "                        if f[i] < BL:\n",
    "                            BL = f[i]\n",
    "                return BL \n",
    "            else:\n",
    "                if stv_abn_per < 20:\n",
    "                    F = 4\n",
    "                if stv_abn_per >= 20 and stv_abn_per < 30:\n",
    "                    F = 2\n",
    "                if stv_abn_per >= 30 and stv_abn_per < 40:\n",
    "                    F = 1\n",
    "                if stv_abn_per >= 40 and stv_abn_per < 60:\n",
    "                    F = 0.5\n",
    "                if stv_abn_per >= 60:\n",
    "                    F = 1   \n",
    "                for i in range(1,imax):\n",
    "                    if f[i] >= 110 and f[i] < BL and h[i] > F*stv_abn_fr*h[0]:\n",
    "                        if f[i] < BL:\n",
    "                            BL = f[i]     \n",
    "                return BL     \n",
    "        else:\n",
    "            for i in range(1,imax):\n",
    "                if f[i] > 110 and h[i] > (1-stv_abn_fr) * (h[0] / 3):\n",
    "                    BL = f[i]\n",
    "                    return BL\n",
    "            for i in range(1,imax):\n",
    "                if f[i] < BL and h[i] > stv_abn_fr * h[0]:\n",
    "                    if f[i] < BL:\n",
    "                        BL = f[i]\n",
    "            return BL    \n",
    "\n",
    "    #Rounding to nearest 50\n",
    "    nfhr = [50 * round(x/50) for x in fhr]\n",
    "    #Re-scaling\n",
    "    nfhr = [x/100 for x in nfhr]\n",
    "    #Counting\n",
    "    h_count = Counter(nfhr)\n",
    "    #Sorting\n",
    "    h_count_sorted = dict(sorted(h_count.items(), key=lambda item: item[1],reverse=True))\n",
    "    #Getting frequencies\n",
    "    h_count_sorted.update((x,100*y/len(fhr)) for x,y in h_count_sorted.items())\n",
    "    #Filtering\n",
    "    hist = dict()\n",
    "    for (key, value) in h_count_sorted.items():\n",
    "        if value >= 0.8:\n",
    "            hist[key] = value\n",
    "    #Driver code\n",
    "    f = list(hist.keys())\n",
    "    h = list(hist.values())\n",
    "    imax = len(f)\n",
    "    BL = f[0]\n",
    "\n",
    "    return find_baseline(f,h,BL,imax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = fhr_baseline_estimation(fhr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h) Detection of accelerations and baseline shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acceleration_detection(fhr, baseline):\n",
    "    #Detection of accelerations\n",
    "    acceleration_intervals = []\n",
    "    i = 0\n",
    "    while i+15*4 < len(fhr):\n",
    "        shifted_fhr = [x-baseline*100 for x in fhr[i:i+15*4]]\n",
    "        if all([x>0 for x in shifted_fhr]) == True:\n",
    "            shift = max(shifted_fhr)\n",
    "            j = i+15*4\n",
    "            while  j<len(fhr) and fhr[j]-baseline*100>0:\n",
    "                if fhr[j]-baseline*100>shift:\n",
    "                    shift = fhr[j]-baseline*100\n",
    "                j = j + 1\n",
    "            if shift > 15*100:\n",
    "                acceleration_intervals.append([i,j])\n",
    "            i = j\n",
    "        else:\n",
    "            i = i + 1\n",
    "    return acceleration_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [],
   "source": [
    "acceleration_intervals = acceleration_detection(fhr, baseline)\n",
    "aceleration_per_second = 4*len(acceleration_intervals)/len(fhr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) Detection and classification of decelerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deceleration_detection(fhr, baseline):\n",
    "    #Detection of decelerations\n",
    "    deceleration_intervals = []\n",
    "    deceleration_total_time = 0\n",
    "    i = 0\n",
    "    while i+15*4 < len(fhr):\n",
    "        shifted_fhr = [x-baseline*100 for x in fhr[i:i+15*4]]\n",
    "        if all([x<0 for x in shifted_fhr]) == True:\n",
    "            shift = min(shifted_fhr)\n",
    "            j = i+15*4\n",
    "            while j<len(fhr) and fhr[j]-baseline*100<0:\n",
    "                if fhr[j]-baseline*100<shift:\n",
    "                    shift = fhr[j]-baseline*100\n",
    "                j = j + 1\n",
    "            if abs(shift) > 15*100:\n",
    "                deceleration_intervals.append([i,j])\n",
    "                deceleration_total_time = deceleration_total_time + j - i\n",
    "            i = j\n",
    "        else:\n",
    "            i = i + 1\n",
    "    return deceleration_intervals, deceleration_total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deceleration_classification(deceleration_intervals):\n",
    "    #Classification of decelerations\n",
    "    mild_decelerations_number = 0\n",
    "    prolongued_decelerations_number = 0\n",
    "    severe_decelerations_number = 0\n",
    "\n",
    "    for d in deceleration_intervals:\n",
    "        diff = d[1] - d[0]\n",
    "        if diff <= 120:\n",
    "            mild_decelerations_number = mild_decelerations_number + 1\n",
    "        elif diff>120 and diff<=300:\n",
    "            prolongued_decelerations_number = prolongued_decelerations_number + 1\n",
    "        elif diff>300:\n",
    "            severe_decelerations_number = severe_decelerations_number + 1\n",
    "    \n",
    "    return mild_decelerations_number, prolongued_decelerations_number, severe_decelerations_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [],
   "source": [
    "def late_deceleration_detection(fhr, baseline):\n",
    "    #Late decelerations\n",
    "    late_deceleration_intervals = []\n",
    "    late_deceleration_total_time = 0\n",
    "    i = 0\n",
    "    while i+15*4 < len(fhr):\n",
    "        shifted_fhr = [x-baseline*100 for x in fhr[i:i+15*4]]\n",
    "        if all([x<0 for x in shifted_fhr]) == True:\n",
    "            shift = min(shifted_fhr)\n",
    "            j = i+15*4\n",
    "            while j<len(fhr) and fhr[j]-baseline*100<0:\n",
    "                if fhr[j]-baseline*100<shift:\n",
    "                    shift = fhr[j]-baseline*100\n",
    "                j = j + 1\n",
    "            if abs(shift) > 15*100:\n",
    "                nadir = min(fhr[i:j])\n",
    "                nadir_ix = fhr.index(nadir)\n",
    "                if nadir_ix-i>30*4 and j-nadir_ix>30*4: \n",
    "                    late_deceleration_intervals.append([i,j])\n",
    "                    late_deceleration_total_time = late_deceleration_total_time + j - i\n",
    "            i = j\n",
    "        else:\n",
    "            i = i + 1\n",
    "\n",
    "    return late_deceleration_intervals, late_deceleration_total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prolongued_deceleration_detection_2(deceleration_intervals):\n",
    "    #prolongued decelerations 2\n",
    "    prolongued_deceleration_intervals = []\n",
    "    prolongued_deceleration_total_time = 0\n",
    "    prolongued_deceleration_longest = 0\n",
    "\n",
    "    for d in deceleration_intervals:\n",
    "        diff = d[1] - d[0]\n",
    "        if diff > 3*60*4:\n",
    "            prolongued_deceleration_total_time = prolongued_deceleration_total_time + diff\n",
    "            prolongued_deceleration_intervals.append(d)\n",
    "            if diff > prolongued_deceleration_longest:\n",
    "                prolongued_deceleration_longest = diff\n",
    "    \n",
    "    return prolongued_deceleration_intervals, prolongued_deceleration_total_time, prolongued_deceleration_longest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [],
   "source": [
    "deceleration_intervals, deceleration_total_time = deceleration_detection(fhr, baseline)\n",
    "\n",
    "mild_decelerations_number, prolongued_decelerations_number, severe_decelerations_number = deceleration_classification(deceleration_intervals)\n",
    "mild_decelerations_number_per_second = 4*mild_decelerations_number/len(fhr)\n",
    "prolongued_decelerations_number_per_second = 4*prolongued_decelerations_number/len(fhr)\n",
    "severe_decelerations_number_per_second = 4*severe_decelerations_number/len(fhr)\n",
    "\n",
    "late_deceleration_intervals, late_deceleration_total_time = late_deceleration_detection(fhr, baseline)\n",
    "prolongued_deceleration_intervals, prolongued_deceleration_total_time, prolongued_deceleration_longest = prolongued_deceleration_detection_2(deceleration_intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h) Detection of abnormal and mean long-term variability (LTV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ltv_calculation(acceleration_intervals, deceleration_intervals, fhr):\n",
    "    def join_intervals(acceleration_intervals, deceleration_intervals):\n",
    "        #Join accelerations and decelerations\n",
    "        acceleration_intervals = interval(*acceleration_intervals)\n",
    "        deceleration_intervals = interval(*deceleration_intervals)\n",
    "        merged_interval = acceleration_intervals | deceleration_intervals\n",
    "        \n",
    "        # start = sorted([x[0] for x in intervals])\n",
    "        # end = sorted([x[1] for x in intervals]) \n",
    "        # merged_interval = []\n",
    "        # j = 0\n",
    "        # new_start = 0\n",
    "\n",
    "        # for i in range(len(start)):\n",
    "        #     if start[i]<end[j]:\n",
    "        #         continue\n",
    "        #     else:\n",
    "        #         j = j + 1\n",
    "        #         merged_interval.append([start[new_start], end[j]])\n",
    "        #         new_start = i\n",
    "\n",
    "        return merged_interval\n",
    "    \n",
    "    def complement_interval(merged):\n",
    "        if len(merged) > 0:\n",
    "            #Get complement of joined interval\n",
    "            start = sorted([x[0] for x in merged])\n",
    "            end = sorted([x[1] for x in merged]) \n",
    "            if start[0] == 0:\n",
    "                start.pop(0)\n",
    "                start.append(len(fhr))\n",
    "            if end[-1] == len(fhr):\n",
    "                end.pop(-1)\n",
    "                end.insert(0,0)\n",
    "\n",
    "            complement_intervals = []\n",
    "            for i in range(len(start)):\n",
    "                complement_intervals.append([end[i],start[i]])\n",
    "        else:\n",
    "            complement_intervals = [[0,len(fhr)]]\n",
    "        \n",
    "        return complement_intervals\n",
    "\n",
    "    #Get ltv\n",
    "    complement_intervals = complement_interval(join_intervals(acceleration_intervals,deceleration_intervals))\n",
    "    ltv = []\n",
    "    for c in complement_intervals:\n",
    "        diff = c[1] - c[0]\n",
    "        if diff >= 60*4:\n",
    "            i = 0\n",
    "            while i+60*4 <= diff:\n",
    "                ls = fhr[i:i+60*4]\n",
    "                max_value = max(ls)\n",
    "                min_value = min(ls)\n",
    "                ltv.append(max_value-min_value)\n",
    "                i = i + 1\n",
    "\n",
    "    if len(ltv) > 0:\n",
    "        #Get ltv mean\n",
    "        ltv_mean = np.mean(ltv)/100\n",
    "        #Get percentage of abnormal ltv\n",
    "        ltv_abnormal_per = 100*len([x for x in ltv if x <= 5*100])/len(ltv)\n",
    "    else:\n",
    "        ltv_mean = 0.0\n",
    "        ltv_abnormal_per = 0.0\n",
    "                \n",
    "    return complement_intervals, ltv_mean, ltv_abnormal_per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduced_variability_check(complement_intervals, deceleration_intervals):\n",
    "    #Get ltv < 5 (reduced variability)\n",
    "    ltv_5_total_time = 0\n",
    "    for c in complement_intervals:\n",
    "        diff = c[1] - c[0]\n",
    "        if diff >= 60*4:\n",
    "            i = 0\n",
    "            while i+60*4 <= diff:\n",
    "                ls = fhr[i:i+60*4]\n",
    "                diff = max(ls) - min(ls)\n",
    "                if diff < 5*100:\n",
    "                    ltv_5_total_time = ltv_5_total_time + 1\n",
    "                i = i + 1\n",
    "\n",
    "    ltv_5_flg = False\n",
    "    if ltv_5_total_time > 50*60*4:\n",
    "        ltv_5_flg = True\n",
    "\n",
    "    #For decelerations\n",
    "    ltv_5_total_time_c = 0\n",
    "    for c in deceleration_intervals:\n",
    "        diff = c[1] - c[0]\n",
    "        if diff >= 60*4:\n",
    "            i = 0\n",
    "            while i+60*4 <= diff:\n",
    "                ls = fhr[i:i+60*4]\n",
    "                diff = max(ls) - min(ls)\n",
    "                if diff < 5*100:\n",
    "                    ltv_5_total_time_c = ltv_5_total_time_c + 1\n",
    "                i = i + 1\n",
    "\n",
    "    ltv_5_flg_c = False\n",
    "    if ltv_5_total_time_c > 3*60*4:\n",
    "        ltv_5_flg_c = True\n",
    "\n",
    "    return ltv_5_flg or ltv_5_flg_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increased_variability_check(complement_intervals):\n",
    "    #Get ltv > 25 (increased variability)\n",
    "    ltv_25_time = 0\n",
    "    for c in complement_intervals:\n",
    "        diff = c[1] - c[0]\n",
    "        if diff >= 60*4:\n",
    "            i = 0\n",
    "            while i+60*4 <= diff:\n",
    "                ls = fhr[i:i+60*4]\n",
    "                diff = max(ls) - min(ls)\n",
    "                if diff > 25*100:\n",
    "                    ltv_25_time = ltv_25_time + 1\n",
    "                i = i + 1\n",
    "\n",
    "    ltv_25_flg = False\n",
    "    if ltv_25_flg > 30*60*4:\n",
    "        ltv_25_flg = True\n",
    "\n",
    "    return ltv_25_flg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "complement_intervals, ltv_mean, ltv_abnormal_per = ltv_calculation(acceleration_intervals, deceleration_intervals, fhr)\n",
    "ltv_5_flg = reduced_variability_check(complement_intervals, deceleration_intervals)\n",
    "ltv_25_flg = increased_variability_check(complement_intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) Histogram properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_properties_calculation(fhr):\n",
    "    #Rounding to nearest 50\n",
    "    nfhr = [50 * round(x/50) for x in fhr]\n",
    "    #Re-scaling\n",
    "    nfhr = [x/100 for x in nfhr]\n",
    "\n",
    "    #Basic Properties\n",
    "    f, v = np.histogram(nfhr,bins=20)\n",
    "    h_min = min(np.delete(v,[0]))\n",
    "    h_max = max(v)\n",
    "    h_width = h_max - h_min\n",
    "\n",
    "    #Peaks\n",
    "    h_peaks = len(find_peaks(f)[0])\n",
    "\n",
    "    #Zeros\n",
    "    h_zeros = 0\n",
    "    i=0\n",
    "    while i < len(f):\n",
    "        if f[i] == 0:\n",
    "            j = i + 1\n",
    "            while j<len(f) and f[j] == 0:\n",
    "                j = j + 1\n",
    "            i = j\n",
    "            h_zeros = h_zeros + 1\n",
    "        else:\n",
    "            i = i + 1\n",
    "\n",
    "    #Stats\n",
    "    h_mean = np.mean(nfhr)\n",
    "    h_mode,_ = stats.mode(nfhr)\n",
    "    h_mode = h_mode[0]\n",
    "    h_median = np.median(nfhr)\n",
    "    h_variance = np.std(nfhr)\n",
    "\n",
    "    #Skew\n",
    "    skew = stats.skew(nfhr)\n",
    "    if skew<0.5 and skew>-0.5:\n",
    "        h_tendency = 0\n",
    "    elif skew>=0.5:\n",
    "        h_tendency = 1\n",
    "    elif skew<=-0.5:\n",
    "        h_tendency = -1\n",
    "\n",
    "    return h_width, h_min, h_max, h_peaks, h_zeros, h_mean, h_mode, h_median, h_variance, h_tendency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_width, h_min, h_max, h_peaks, h_zeros, h_mean, h_mode, h_median, h_variance, h_tendency = histogram_properties_calculation(fhr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j) Fetal Health"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./files/fetal_health.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contractions association\n",
    "def interval_common(contraction_intervals,contraction_total_time,itvl):\n",
    "    contraction_intervals = interval(*contraction_intervals)\n",
    "    itvl = interval(*itvl)\n",
    "    intersection = contraction_intervals&itvl\n",
    "    intersection_total_time = 0\n",
    "    for i in intersection:\n",
    "        d =  i[1] - i[0]\n",
    "        intersection_total_time = intersection_total_time + d\n",
    "    if contraction_total_time > 0:\n",
    "        return intersection_total_time/contraction_total_time\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetal_health_fn(baseline, ltv_5_flg, ltv_25_flg, prolongued_deceleration_longest, contraction_intervals, contraction_total_time, late_deceleration_intervals, late_deceleration_total_time, prolongued_deceleration_intervals, prolongued_deceleration_total_time, ltv_mean, deceleration_intervals):\n",
    "    #pathological\n",
    "    baseline_tf = baseline<100\n",
    "    variability_tf = ltv_5_flg or ltv_25_flg\n",
    "    repetitive_tf = False\n",
    "    if prolongued_deceleration_longest > 5*60*4:\n",
    "        repetitive_tf = True   \n",
    "    elif ltv_5_flg == True:\n",
    "        if interval_common(contraction_intervals,contraction_total_time,late_deceleration_intervals) > 0.5 and late_deceleration_total_time > 20*60*4:\n",
    "            repetitive_tf = True\n",
    "        elif interval_common(contraction_intervals,contraction_total_time,prolongued_deceleration_intervals) > 0.5 and prolongued_deceleration_total_time > 20*60*4:\n",
    "            repetitive_tf = True\n",
    "    else:\n",
    "        if interval_common(contraction_intervals,contraction_total_time,late_deceleration_intervals) > 0.5 and late_deceleration_total_time > 30*60*4:\n",
    "            repetitive_tf = True\n",
    "        elif interval_common(contraction_intervals,contraction_total_time,prolongued_deceleration_intervals) > 0.5 and prolongued_deceleration_total_time > 30*60*4:\n",
    "            repetitive_tf = True\n",
    "    if baseline_tf or variability_tf or repetitive_tf == True:\n",
    "        return 3\n",
    "\n",
    "    #normal\n",
    "    baseline_tf = baseline>=110 and baseline<=160\n",
    "    variability_tf = ltv_mean>=5 and ltv_mean<=25\n",
    "    repetitive_tf = interval_common(contraction_intervals,contraction_total_time,deceleration_intervals) <= 0.5\n",
    "    if all([baseline_tf,variability_tf,repetitive_tf]) == True:\n",
    "        return 1\n",
    "    \n",
    "    #suspicious\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetal_health = fetal_health_fn(baseline, ltv_5_flg, ltv_25_flg, prolongued_deceleration_longest, contraction_intervals, contraction_total_time, late_deceleration_intervals, late_deceleration_total_time, prolongued_deceleration_intervals, prolongued_deceleration_total_time, ltv_mean, deceleration_intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k) Creating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_files = []\n",
    "hea_files = []\n",
    "for root, directories, files in os.walk(\"./physionet_dataset_processed\"):\n",
    "\tfor name in files:\n",
    "\t\tif \".mat\" in name:\n",
    "\t\t\tmat_files.append(os.path.join(root, name))\n",
    "\t\telif \".hea\" in name:\n",
    "\t\t\thea_files.append(os.path.join(root, name))\n",
    "mat_files = sorted(mat_files)\n",
    "hea_files = sorted(hea_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for file in mat_files:\n",
    "    mat = scipy.io.loadmat(file)\n",
    "\n",
    "    fhr = fhr_spike_removal(mat)\n",
    "\n",
    "    uc = filter_uterine_contractions(mat)\n",
    "\n",
    "    contraction_intervals, contraction_total_time = uterine_contraction_detection(uc)\n",
    "    contraction_number_per_second = 4*len(contraction_intervals)/len(uc)\n",
    "\n",
    "    stv_mean, stv_abn_per = stv_calculation(fhr)\n",
    "\n",
    "    fhr = filter_fhr_signals(fhr)\n",
    "\n",
    "    baseline = fhr_baseline_estimation(fhr)\n",
    "\n",
    "    acceleration_intervals = acceleration_detection(fhr, baseline)\n",
    "    aceleration_per_second = 4*len(acceleration_intervals)/len(fhr)\n",
    "\n",
    "    deceleration_intervals, deceleration_total_time = deceleration_detection(fhr, baseline)\n",
    "    mild_decelerations_number, prolongued_decelerations_number, severe_decelerations_number = deceleration_classification(deceleration_intervals)\n",
    "    mild_decelerations_number_per_second = 4*mild_decelerations_number/len(fhr)\n",
    "    prolongued_decelerations_number_per_second = 4*prolongued_decelerations_number/len(fhr)\n",
    "    severe_decelerations_number_per_second = 4*severe_decelerations_number/len(fhr)\n",
    "    late_deceleration_intervals, late_deceleration_total_time = late_deceleration_detection(fhr, baseline)\n",
    "    prolongued_deceleration_intervals, prolongued_deceleration_total_time, prolongued_deceleration_longest = prolongued_deceleration_detection_2(deceleration_intervals)\n",
    "\n",
    "    complement_intervals, ltv_mean, ltv_abnormal_per = ltv_calculation(acceleration_intervals, deceleration_intervals, fhr)\n",
    "    ltv_5_flg = reduced_variability_check(complement_intervals, deceleration_intervals)\n",
    "    ltv_25_flg = increased_variability_check(complement_intervals)\n",
    "\n",
    "    h_width, h_min, h_max, h_peaks, h_zeros, h_mean, h_mode, h_median, h_variance, h_tendency = histogram_properties_calculation(fhr)\n",
    "\n",
    "    fetal_health = fetal_health_fn(baseline, ltv_5_flg, ltv_25_flg, prolongued_deceleration_longest, contraction_intervals, contraction_total_time, late_deceleration_intervals, late_deceleration_total_time, prolongued_deceleration_intervals, prolongued_deceleration_total_time, ltv_mean, deceleration_intervals)    \n",
    "    \n",
    "    row = [baseline, aceleration_per_second, None, contraction_number_per_second, mild_decelerations_number_per_second, severe_decelerations_number_per_second, prolongued_decelerations_number_per_second, stv_abn_per, stv_mean, ltv_abnormal_per, ltv_mean, h_width, h_min, h_max, h_peaks, h_zeros, h_mode, h_mean, h_median, h_variance, h_tendency, fetal_health]\n",
    "\n",
    "    result.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(data=result,columns=[\"baseline value\",\"accelerations\",\"fetal_movement\",\"uterine_contractions\",\"light_decelerations\",\"severe_decelerations\",\"prolongued_decelerations\",\"abnormal_short_term_variability\",\"mean_value_of_short_term_variability\",\"percentage_of_time_with_abnormal_long_term_variability\",\"mean_value_of_long_term_variability\",\"histogram_width\",\"histogram_min\",\"histogram_max\",\"histogram_number_of_peaks\",\"histogram_number_of_zeroes\",\"histogram_mode\",\"histogram_mean\",\"histogram_median\",\"histogram_variance\",\"histogram_tendency\",\"fetal_health\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAT files with no UC signal (deleted)\n",
    "1104\n",
    "1119\n",
    "1149\n",
    "1155\n",
    "1186\n",
    "1188\n",
    "1258\n",
    "1327"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l) Other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other info\n",
    "result = []\n",
    "for file in hea_files:\n",
    "    f = open(file, 'r')\n",
    "    lines = f.readlines()\n",
    "    cnt = 0\n",
    "    for line in lines:\n",
    "        if \"#pH\" in line:\n",
    "            val_1 = float(line.strip(\"#pH\").strip())\n",
    "            continue\n",
    "        if \"#BDecf\" in line:\n",
    "            val_2 = float(line.strip(\"#BDecf\").strip())\n",
    "            continue\n",
    "        if \"#pCO2\" in line:\n",
    "            val_3 = float(line.strip(\"#pCO2\").strip())\n",
    "            continue\n",
    "        if \"#BE\" in line:\n",
    "            val_4 = float(line.strip(\"#BE\").strip())\n",
    "            continue\n",
    "        if \"#Apgar1\" in line:\n",
    "            val_5 = int(line.strip(\"#Apgar1\").strip())\n",
    "            continue\n",
    "        if \"#Apgar5\" in line:\n",
    "            val_6 = int(line.strip(\"#Apgar5\").strip())\n",
    "            continue\n",
    "        if \"#Gest. weeks\" in line:\n",
    "            val_7 = int(line.strip(\"#Gest. weeks\").strip())\n",
    "            continue\n",
    "        if \"#Weight(g)\" in line:\n",
    "            try:\n",
    "                val_8 = int(line.strip(\"#Weight(g)\").strip())\n",
    "            except:\n",
    "                val_8 = None\n",
    "            continue\n",
    "        if \"#Sex\" in line:\n",
    "            val_9 = int(line.strip(\"#Sex\").strip())\n",
    "            continue\n",
    "        if \"#Age\" in line:\n",
    "            val_10 = int(line.strip(\"#Age\").strip())\n",
    "            continue\n",
    "        if \"#Gravidity\" in line:\n",
    "            try:\n",
    "                val_11 = int(line.strip(\"#Gravidity\").strip())\n",
    "            except:\n",
    "                val_11 = None\n",
    "            continue\n",
    "        if \"#Parity\" in line:\n",
    "            val_12 = int(line.strip(\"#Parity\").strip())\n",
    "            continue\n",
    "        if \"#Diabetes\" in line:\n",
    "            val_13 = int(line.strip(\"#Diabetes\").strip())\n",
    "            continue\n",
    "        if \"#Hypertension\" in line:\n",
    "            val_14 = int(line.strip(\"#Hypertension\").strip())\n",
    "            continue\n",
    "        if \"#Preeclampsia\" in line:\n",
    "            val_15 = int(line.strip(\"#Preeclampsia\").strip())\n",
    "            continue\n",
    "        if \"#Liq. praecox\" in line:\n",
    "            val_16 = int(line.strip(\"#Liq. praecox\").strip())\n",
    "            continue\n",
    "        if \"#Pyrexia\" in line:\n",
    "            val_17 = int(line.strip(\"#Pyrexia\").strip())\n",
    "            continue\n",
    "        if \"#Meconium\" in line:\n",
    "            val_18 = int(line.strip(\"#Meconium\").strip())\n",
    "            continue\n",
    "        if \"#Presentation\" in line:\n",
    "            try:\n",
    "                val_19 = int(line.strip(\"#Presentation\").strip())\n",
    "            except:\n",
    "                val_19 = None\n",
    "            continue\n",
    "        if \"#Induced\" in line:\n",
    "            val_20 = int(line.strip(\"#Induced\").strip())\n",
    "            continue\n",
    "        if \"#I.stage\" in line:\n",
    "            val_21 = int(line.strip(\"#I.stage\").strip())\n",
    "            continue\n",
    "        if \"#NoProgress\" in line:\n",
    "            val_22 = int(line.strip(\"#NoProgress\").strip())\n",
    "            continue\n",
    "        if \"#CK/KP\" in line:\n",
    "            val_23 = int(line.strip(\"#CK/KP\").strip())\n",
    "            continue\n",
    "        if \"#II.stage\" in line:\n",
    "            val_24 = int(line.strip(\"#II.stage\").strip())\n",
    "            continue\n",
    "        if \"#Deliv. type\" in line:\n",
    "            val_25 = int(line.strip(\"#Deliv. type\").strip())\n",
    "            continue\n",
    "\n",
    "        continue\n",
    "    result.append([val_1, val_2, val_3, val_4, val_5, val_6, val_7, val_8, val_9, val_10, val_11, val_12, val_13, val_14, val_15, val_16, val_17, val_18, val_19, val_20, val_21, val_22, val_23, val_24, val_25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apgar = pd.DataFrame(data=result, columns=[\"pH\",\"BDecf\",\"pCO2\",\"BE\",\"Apgar1\", \"Apgar5\", \"Gest. weeks\", \"Weight(g)\", \"Sex\", \"Age\", \"Gravidity\", \"Parity\", \"Diabetes\", \"Hypertension\", \"Preeclampsia\", \"Liq. praecox\", \"Pyrexia\", \"Meconium\", \"Presentation\", \"Induced\", \"I.stage\", \"NoProgress\", \"CK/KP\", \"II.stage\", \"Deliv. type\"])\n",
    "dataset = pd.merge(dataset, apgar, left_index=True, right_index=True)\n",
    "dataset.to_csv(\"./second_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./files/apgar.png)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac750e7546c43045a4c2a4a51d6ff271a4f7806cc184dcaeaa8a03025e690f95"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
